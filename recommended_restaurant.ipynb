{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ce6486b5d3b85ae3569a71668603863957f45d32"
   },
   "source": [
    "I would like to highlight the core idea: First, we want to find a way to represent reviews using a bag-of-words representation. After doing so, we will also represent categories using a one-hot encoding representation. Then, we can manipulate those representations to find similarities and differences while balancing the weights of the two. Note that the core idea assume that you are more likely to love a restaurant if its reviews are similar to the reviews of the restaurants you already love."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5525c77bf96337f1f21d78df993d38e482b9b308"
   },
   "source": [
    "Let's begin by importing libraries and making sure we only deal with valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c8b0a68b09ee8fecbbfccdbeb300b63205e542d"
   },
   "outputs": [],
   "source": [
    "df_yelp_business = pd.read_json('../input/yelp_academic_dataset_business.json', lines=True)\n",
    "df_yelp_business.fillna('NA', inplace=True)\n",
    "# we want to make sure we only work with restaurants -- nothing else\n",
    "df_yelp_business = df_yelp_business[df_yelp_business['categories'].str.contains('Restaurants')]\n",
    "print('Final Shape: ',df_yelp_business.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2a6fee5c004788aaff55656025270d0adf7c3747"
   },
   "source": [
    "Now we bring the reviews and perform some preprocessing on those reviews.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "508d28c7fdb9065e3dbaf0a39472297fc3b292cf"
   },
   "outputs": [],
   "source": [
    "df_yelp_review_iter = pd.read_json('../input/yelp_academic_dataset_review.json', chunksize=100000, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c6689f58f21411bac18026ba6edfbd0248a8b2f8"
   },
   "source": [
    "Because reviews are too big, we will read them in chunks, and make sure we delete reviews of places that are not in our list of businesses filtered earlier. Note here we choose 5 chunks, but we could have chosen any number (larger numbers will give MemoryError later on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70007e05b3f8828eb82cc4c4f926f8e657861adb"
   },
   "outputs": [],
   "source": [
    "df_yelp_review = pd.DataFrame()\n",
    "i=0\n",
    "for df in df_yelp_review_iter:\n",
    "    df = df[df['business_id'].isin(df_yelp_business['business_id'])]\n",
    "    df_yelp_review = pd.concat([df_yelp_review, df])\n",
    "    i=i+1\n",
    "    print(i)\n",
    "    if i==4: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85169d7858504ee719c36e795ba46f8eb9a3c909"
   },
   "source": [
    "Also make sure we only get businesses that already show up in our review list and delete the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1aad8f5fe22db8c3940e07fc3ae49d94000725bf"
   },
   "outputs": [],
   "source": [
    "df_yelp_business = df_yelp_business[df_yelp_business['business_id'].isin(df_yelp_review['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6385a3d6f0f21f722925451ecf38ff5c90647b21"
   },
   "outputs": [],
   "source": [
    "print('Final businesses shape: ', df_yelp_business.shape)\n",
    "print('Final review shape: ', df_yelp_review.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "06b970d40d99d889f4483913fb21ab9a50f8f86d"
   },
   "source": [
    "Now we want to processes reviews in a reasonable way. The following function is adopted from [here](https://github.com/msahamed/yelp_comments_classification_nlp/blob/master/word_embeddings.ipynb) which really does a good deal to preprocess the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c422664f62cf00325e65e3d65cb2cc324e6e229e"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    \n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b5994feb7446844b74c9696e197fe0e1673de72"
   },
   "source": [
    "The next step will apply those transformations. Note that it will take a couple of minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02466c2f2dcce172f7c0cc655b8274187fbb0c12"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_yelp_review['text'] = df_yelp_review['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "877c084718b30dea58f6f929882211831d01a8ae"
   },
   "source": [
    "Now we want to vectorize both reviews and categories. Note that min_df and max_df arguments in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85e8d4363daba09a4835ec15b63c6f42b475f93d"
   },
   "outputs": [],
   "source": [
    "vectorizer_reviews = CountVectorizer(min_df = .01,max_df = .99, tokenizer = WordPunctTokenizer().tokenize)\n",
    "vectorized_reviews = vectorizer_reviews.fit_transform(df_yelp_review['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bc3440bda9e0c63df3e0fdc65b8dc5767e06b5f4"
   },
   "outputs": [],
   "source": [
    "print(vectorized_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aeccafffd14bdc0a3bbe45b98013129baf64c973"
   },
   "source": [
    "Show top 100 vocabularies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4e5b9ac45228628c4e4dc1423b5d60e35ea4722"
   },
   "outputs": [],
   "source": [
    "' | '.join(vectorizer_reviews.get_feature_names()[:100]) # only the first 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16be9c9210be0b11d2a3a54408329331dc4cc325"
   },
   "outputs": [],
   "source": [
    "vectorizer_categories = CountVectorizer(min_df = 1, max_df = 1., tokenizer = lambda x: x.split(', '))\n",
    "vectorized_categories = vectorizer_categories.fit_transform(df_yelp_business['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "999758041a63677eb037437203d3904fc8dfb70a"
   },
   "outputs": [],
   "source": [
    "print(vectorized_categories.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b4066f4c766a6d5cb4b0db59ec8c15023d273844"
   },
   "source": [
    "We also show 100 categories.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "728980aaa816aacc80d548a965b589f91e6e68e9"
   },
   "outputs": [],
   "source": [
    "' | '.join(vectorizer_categories.get_feature_names()[:100]) # only the first 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "66af894d9c953efa181e0e449e388314eb0a9b36"
   },
   "source": [
    "We will use sparse representations to make dot products easier to speed up dot products (and also save memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a9f9b515fd5f5ba86d24b32bcd5823100dd82bd"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from scipy import sparse\n",
    "businessxreview = sparse.csr_matrix(pd.get_dummies(df_yelp_review['business_id']).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "804981e9ae1f50a57cccf851bde93ca281035722"
   },
   "source": [
    "Let's print out the shapes of the matrices we have prepared and make sure they make sense (by matching their dimensions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9890695225fbbc6d1dc9822184373c2e936631bf"
   },
   "outputs": [],
   "source": [
    "print('restuarants x categories: \\t', vectorized_categories.shape) \n",
    "print('restuarants x reviews: \\t\\t' , businessxreview.shape) \n",
    "print('reviews x words: \\t\\t', vectorized_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "27097297ed3ba509045cf848d761db9d39860d1b"
   },
   "source": [
    "Now we are ready to choose a seed restaurant and find  other restaurants that might be as good as the seed restaurant. We make sure to choose a restaurant with good number of reviews and ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a8d5c1ae8f0ca0af2da498f06668554194ee594"
   },
   "outputs": [],
   "source": [
    "# to choose a restaurant, just copy the business id and paste it in the next cell\n",
    "# you can always rerun the cell to choose another restuarant. \n",
    "df_yelp_business.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e82d082208d30f99a90e97b6cdb801952e087b15",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "business_choose = 'aUrOyWFKxKeVXiFzwbTXSA' # vegan, vegetarian, cafes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "80cde331c86c16d4d71a649f048425b2ec46ba52"
   },
   "source": [
    "First, we pull up the reivews and then show some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9fe93d1643757dd3304914c833efc04cea4c50de"
   },
   "outputs": [],
   "source": [
    "new_reviews = df_yelp_review.loc[df_yelp_review['business_id'] == business_choose, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8dc2541edd9d7d9360bdae68d792652e76543b4c"
   },
   "outputs": [],
   "source": [
    "print('\\n'.join([r[:100] for r in new_reviews.tolist()])) # restaurant reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b01898d63f2727606f4f3f480ba12b524eced878"
   },
   "source": [
    "Then we pull up the categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b2411a142b5f4b3f35d65578d049815080b1ae07"
   },
   "outputs": [],
   "source": [
    "new_categories = df_yelp_business.loc[df_yelp_business['business_id'] == business_choose, 'categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f0cf58f526da537fb620c0d39c4862bed7ea873"
   },
   "outputs": [],
   "source": [
    "new_categories.tolist() #  restaurant categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c6fed5c06f9404c42f69c982036a10a9ee9b21d7"
   },
   "source": [
    "Here, we compute two sets of distancecs: we compute the correlation distance of the average vectorized reviews to all the reviews, and compute the correlation distance between this category and all other categories. The category trick will be clearer when we see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92237d3dacd2acc24169d41c5887f0b46d1feaf3"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "# find most similar reviews\n",
    "dists1 = cdist(vectorizer_reviews.transform(new_reviews).todense().mean(axis=0), \n",
    "              vectorized_reviews.T.dot(businessxreview).T.todense(), \n",
    "               metric='correlation')\n",
    "# find most similar categories\n",
    "dists2 = cdist(vectorizer_categories.transform(new_categories).todense().mean(axis=0), \n",
    "              vectorized_categories.todense(), \n",
    "               metric='correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e25578261fea8c2e89c44a7a2a6680d09683c06"
   },
   "source": [
    "Now we combine the two sets of distances and take the average of those (we can take other metrics such as min or max, depending on your priority)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a0a6a140460bc8cdb96008a90f22d0b3cc451bf"
   },
   "outputs": [],
   "source": [
    "# combine the two vectors in one matrix\n",
    "dists_together = np.vstack([dists1.ravel(), dists2.ravel()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42aedd72bd2ffd64b496eaac3ce994d75b6c1afb"
   },
   "outputs": [],
   "source": [
    "dists_together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0785ddc0dbb7030c1c8fa5ca7e59b52460b0916"
   },
   "outputs": [],
   "source": [
    "# this is a key cell: how are we going to prioritize ?\n",
    "dists = dists_together.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d92a6136d5516dc009e5815cc9d713e83efe618a"
   },
   "outputs": [],
   "source": [
    "dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "30d6ecc96ded703acdad3ea19e6e7fcb3a69e6a4"
   },
   "source": [
    "Let's select the closest 5 restaurants to the seed restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f13e5bf777479c5854c392897621a1cb6efd300"
   },
   "outputs": [],
   "source": [
    "# select the closest 5\n",
    "closest = dists.argsort().ravel()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ecf8e9af29ed4297bf52626fb12442e36f943546"
   },
   "source": [
    "Here is our seed restaurant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2f35a231e044d1db227f669e402df12dd3a78be"
   },
   "outputs": [],
   "source": [
    "df_yelp_business.loc[df_yelp_business['business_id']== business_choose, ['business_id', 'categories', 'name', 'stars']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d3faafa156f20c890fccc33a0d7e966198a564c"
   },
   "source": [
    "Now let's see what the top matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a207095cce600b7a3db0e426a3e9ce4ec07b5bf7"
   },
   "outputs": [],
   "source": [
    "df_yelp_business.loc[df_yelp_business['business_id'].isin(df_yelp_business['business_id'].iloc[closest]), ['business_id', 'categories', 'name', 'stars']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4e2b6a30a0d1ebd6b140af178bc196bcc5b57dcf"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
